# My First Large Language Model (LLM)
Over the holidays, I had studied much on large language models and this has 
become very interesting to me. 

## Project Details
For this project, I am using the Google Generative AI services, specificall gemini AI - the model for this project is the `gemini-1.5-flash` model, who API I have free access to for a benchmarked Tests Per Minute.

The code is to be run locally on my device's CLI for now, I hope to implemment more complexities to the code base as I progress on this journey, I hope to implement the following:
1. Add the front end to the code using streamlit and/or FastAPI and/or either of Flask and Django.
2. Add a framework such as langchain to implement greater complexities and possibly implement a Retrieval Augmented Generation concept to the code base.
. . .

The requirements.txt file houses all of the required dependencies for the code, so reimplenting is just a simple `pip freeze -r requirements.txt` away.

To run the code, you can just go to the directly where the files are located via your CLI and run a simple 
                        `python main.py` on a windows machine and
                        `python3 main.py` on other operating systems.